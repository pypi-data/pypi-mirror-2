==============
 Data objects
==============

Data objects create chunk objects to support file sizes up to 10
MB to be stored.

    >>> from lovely.gae.snapshot.chunk import Data, Chunk

We can create a Data object via its store method.

    >>> d1 = Data.store('abc')

The data is known by its sha1 hexdigest.

    >>> d1
    <Data sha1:a9993e364706816aba3e25717850c26c9cd0d89d>

    >>> d1.length == len(d1) == 3
    True

The get_data method returns a cached stringio object.

    >>> d1.get_data()
    <StringIO.StringIO instance at ...>
    >>> d1.get_data() is d1.get_data()
    True

If we store the same data twice we get an existing data object, so no
new one is created.

    >>> Data.all().count()
    1
    >>> d1 = Data.store('abc')
    >>> Data.all().count()
    1

The position of the stream is always reset to 0.

    >>> d1.get_data().seek(10)
    >>> d1.get_data().tell()
    0

    >>> d = d1.get_data()
    >>> d.read()
    'abc'

The digests of its chunks can be accessed. In this case the digest is
exatly the digest of the one and only chunk.

    >>> d1.chunks
    [u'sha1:a9993e364706816aba3e25717850c26c9cd0d89d']

Lets create a bigger file.

    >>> data = 'A' * 1024 * 1024 * 5
    >>> d2 = Data.store(data)

    >>> len(d2) == 1024 *1024 *5
    True
    >>> import hashlib
    >>> h = hashlib.sha1(data).hexdigest()

Note that also chunks are not created twice.

    >>> d2.chunks
    [u'sha1:22e28a39b260f9e4bf93a7133ddc3536f87615c5',
    u'sha1:22e28a39b260f9e4bf93a7133ddc3536f87615c5',
    u'sha1:22e28a39b260f9e4bf93a7133ddc3536f87615c5',
    u'sha1:22e28a39b260f9e4bf93a7133ddc3536f87615c5',
    u'sha1:22e28a39b260f9e4bf93a7133ddc3536f87615c5',
    u'sha1:025a0f85bf7271624234f02d31ecdf43e5aee1d8']

    >>> Chunk.all().count()
    3

    >>> d2.key().name()[5:] == h
    True

The data contains of course all the data of all chunks.

    >>> h == hashlib.sha1(d2.get_data().read()).hexdigest()
    True

